import pandas as pd
import numpy as np
import math
from scipy.stats import norm
import numpy as np
import matplotlib.pyplot as plt
import datetime
import time

def prepare_discount_factors(St_d):

    discount_factors = St_d[~(St_d['risk_factor'].isin(['usd', 'eur', 'rub']))].copy()
    discount_factors['risk_factor'] = discount_factors['risk_factor'].astype(float)
    discount_factors['gap_date'] = discount_factors.apply(lambda row: row['forward_date'] + datetime.timedelta(days=round(365 * row['risk_factor'])), axis=1)
    discount_factors = discount_factors.sort_values(by=['gap_date'])
    discount_factors['bidval'] = np.exp(-1 * discount_factors['value']/100*((discount_factors['gap_date'] - discount_factors['forward_date']).dt.days)/365)
    discount_factors['next_gap_date'] = discount_factors['gap_date'].shift(-1)
    discount_factors['next_risk_factor'] = discount_factors['risk_factor'].shift(-1)
    discount_factors['next_bidval'] = discount_factors['bidval'].shift(-1)
    discount_factors['next_bidval'] = discount_factors['next_bidval'].fillna(0)
    discount_factors = discount_factors.rename(columns={"gap_date": "prev_gap_date"})
    return discount_factors

def join_fx(deals, St):
    St = St[St['risk_factor'].isin(['usd', 'eur'])].copy()
    deals = deals.merge(St[['forward_date', 'risk_factor', 'value']], how='left', left_on=['forward_date', 'ccy'], right_on=['forward_date', 'risk_factor']).drop('risk_factor', axis = 1)
    deals['value'] = deals['value'].fillna(1)
    return deals

def join_df(cash_flow_full, discount_factors, cf_date_type = 'mat_date', suffix = '_fxd'):
    discount_factors = prepare_discount_factors(discount_factors)
    cash_flow_full_df = cash_flow_full.merge(discount_factors[['bidval', 'next_bidval', 'forward_date', 'prev_gap_date', 'next_gap_date']],
                                                   how='left', left_on=['forward_date'],
                                          right_on = ['forward_date'])

    cash_flow_full_df = cash_flow_full_df[(cash_flow_full_df['prev_gap_date'] <= cash_flow_full_df['mat_date'])
                                                & (cash_flow_full_df['mat_date'] <
                                                   cash_flow_full_df['next_gap_date'])].rename(
                                                columns={"bidval": "bidval" + suffix,
                                                         "next_bidval": "next_bidval" + suffix,
                                                         "prev_gap_date": "prev_gap_date" + suffix,
                                                         "next_gap_date": "next_gap_date" + suffix})
    interpolate_df(cash_flow_full_df, cf_date_type, suffix)
    return cash_flow_full_df

def interpolate_df(data, cf_date, suffix = ''):
    data['year_frac_t1'] = (data['prev_gap_date' + suffix] - (data['forward_date'])).dt.days / 365.0
    data['year_frac_t2'] = (data['next_gap_date' + suffix] - data['forward_date']).dt.days / 365.0
    data['year_frac_t0'] = (data[cf_date] - data['forward_date']).dt.days / 365.0
    data['z1'] = -(1 / data['year_frac_t1']) * np.log(data['bidval'  + suffix].astype(float))
    data['z2'] = -(1 / data['year_frac_t2']) * np.log(data['next_bidval'  + suffix].astype(float))
    data.loc[data['z1'].isnull(), 'z1'] = data.loc[data['z1'].isnull(), 'z2']
    data.loc[data['bidval' + suffix] == 1, 'z1'] = data.loc[data['bidval' + suffix] == 1, 'z2']
    data['z0'  + suffix] = (data['z2'] * (data['year_frac_t0'] - data['year_frac_t1']) +
                 data['z1']  * (data['year_frac_t2'] - data['year_frac_t0'])) / \
                           (data['year_frac_t2'] - data['year_frac_t1'])
    data['discount_factor' + suffix] = np.exp(-data['year_frac_t0'] * data['z0' + suffix])
    data['discount_factor' + suffix] = data['discount_factor' + suffix].fillna (1)

def cycle_for_csa(deals_csa, forward_date_list, St_d):
    today = forward_date_list[0]
    mpor = today + datetime.timedelta(days=14)
    forward_date_list_for_csa = list(filter(lambda x: x <= mpor, forward_date_list))
    for d in forward_date_list_for_csa:
        print('csa:', d)


def main(St, deals):
    deals_all = pd.DataFrame()
    forward_date_list = list(set(St['forward_date']))
    forward_date_list.sort()
    #deals_csa = deals[deals['csa'] == 'Y'].copy()
    #deals_csa = cycle_for_csa(deals_csa, forward_date_list, St_d)
    #deals = deals[deals['csa'] == 'N']
    for d in forward_date_list:
        #print(d)
        St_d = St[St['forward_date'] == d].copy()
        deals_mtm = mtm_calc(deals, St_d, d)
        deals_mtm['forward_date'] = d
        deals_all = pd.concat([deals_all, deals_mtm])
    deals_csa = deals_all[deals_all['csa'] == 'Y'].copy()
    deals_all = deals_all[deals_all['csa'] == 'N']
    deals_csa_pfe_limited = csa_pfe_limitation(deals_csa, forward_date_list)
    deals_all = pd.concat([deals_all, deals_csa_pfe_limited])
    return deals_all

def csa_pfe_limitation(deals, forward_date_list):
    deals = deals.sort_values(by=['client', 'forward_date'])
    deals['mtm_adjusted'] = deals.groupby('client')['mtm'].transform(lambda x: x - x.iloc[0]) # because varmargin covers current MtM revaluation
    deals['mtm'] = deals['mtm_adjusted']
    deals.drop(['mtm_adjusted'], axis=1)
    today = forward_date_list[0]
    mpor_date = today + datetime.timedelta(days=14) #RISDA margin period of risk is 14 days
    mask = deals['forward_date'] > mpor_date
    mpor_mtm = deals[deals['forward_date'] == mpor_date].set_index('client')['mtm']
    deals.loc[mask, 'mtm'] = deals.loc[mask, 'client'].map(mpor_mtm)
    1==1
    return deals
    #deals[mpor_pfe] =

def mtm_calc(deals, St_d, d):
    deals['days'] = (deals['mat_date'] - d).dt.days
    deals['forward_date'] = d
    deals = join_df(deals, St_d, cf_date_type='mat_date')
    deals = join_fx(deals, St_d)
    deals['mtm'] = deals['amt'] * deals['discount_factor_fxd'] * deals['value']
    deals = deals.groupby(['client', 'csa'], as_index=False).agg({'mtm': 'sum'}).reset_index()   #отсюда убрал продукт
    return deals

def parce_rf(St, col_names, report_date):
    St_df = pd.DataFrame(St, columns=col_names)
    melted_St = St_df.melt(id_vars=['time_delta'], var_name='risk_factor', value_name='value')
    melted_St.reset_index(drop=True, inplace=True)
    melted_St['forward_date'] = melted_St.apply(lambda row: report_date + datetime.timedelta(days=round(365 * row['time_delta'])), axis=1)
    melted_St.drop('time_delta', axis=1, inplace=True)
    return melted_St



#get deals
deals = pd.read_excel('/Users/mihailzaytsev/Desktop/Диссер_мага/deals_for_GBM_2_cust.xlsx', engine='openpyxl')
deals['mat_date'] = pd.to_datetime(deals['mat_date'])

#get market data
data_ir = pd.read_excel('/Users/mihailzaytsev/Desktop/Диссер_мага/market_data_gcurve.xlsx', engine='openpyxl')
data_fx = pd.read_excel('/Users/mihailzaytsev/Desktop/Диссер_мага/market_data_fx.xlsx', engine='openpyxl')

dates_df = set(data_ir['tradedate'])
dates_df = pd.DataFrame(dates_df, columns = ['tradedate'])

period_list = set(data_ir['period'])

for p in period_list: #to get risk factors in matrix form
    p_df = data_ir[data_ir['period'] == p].copy()
    p_df = p_df.rename(columns = {'value': p})
    p_df.drop(['tradetime', 'period'], axis= 1, inplace= True)
    dates_df = pd.merge(dates_df, p_df, how = 'left', on = 'tradedate')

usd_rub = (data_fx[data_fx['secid'] == 'USDFIXME']).rename(columns = {'rate': 'usd'})
usd_rub.drop('secid', axis= 1 , inplace= True )
eur_rub = (data_fx[data_fx['secid'] == 'EURFIXME']).rename(columns = {'rate': 'eur'})
eur_rub.drop('secid', axis= 1 , inplace= True )

fx_df = pd.merge(usd_rub, eur_rub, how = 'left', on = 'tradedate')
all_df = pd.merge(fx_df, dates_df, how = 'left', on = 'tradedate')
report_date = all_df['tradedate'].iloc[-1]
report_date = datetime.datetime.strptime(report_date, '%Y-%m-%d')

all_df.drop('tradedate', axis= 1, inplace= True)
all_df_col_names = all_df.columns.tolist()
all_df_col_names.append('time_delta')

df_log_returns = all_df.apply(lambda x: (np.log(x / x.shift(1))).fillna(0), axis=0)

#####################
# find necessary parametres of input market data
num_sims = 300
years = 2
steps = 52 * years + 1
steps = int(steps)
num_of_risk_factors = df_log_returns.shape[1]

meanReturns = df_log_returns.mean() * 5
sdrt_div = df_log_returns.std() * math.sqrt(5)
covMatrix = df_log_returns.cov()
corrMatrix = df_log_returns.corr()

S0 = ((all_df.iloc[-1]).to_numpy()).T # here changed df_log_returns =>
dt = 1/((steps-1)/years)
chol = np.linalg.cholesky(corrMatrix) #get cholezky decomposition to mind the correlation of fx and ir epsilons

#convert to arrays
mean_returns_col = meanReturns.to_numpy()
sdrt_div_col = sdrt_div.to_numpy()

n = 0
st = time.time()
St_full = np.empty([steps, num_of_risk_factors])
mtm_generated = pd.DataFrame()
while n < num_sims:
    #generate standard normal non-correlated outcomes
    uncrlted_eps = np.random.normal(size=(steps-1, df_log_returns.shape[1]))

    #correlate them through cholezky matrix
    crlted_eps = (chol @ uncrlted_eps.T)

    #some adjustments
    num_columns = crlted_eps.shape[1]
    sdrt_div_col_reshaped = (np.tile(sdrt_div_col, (num_columns, 1))).T

    #calculation of gbm
    drift = (mean_returns_col - sdrt_div_col ** 2 / 2) * dt
    drift_reshaped = (np.tile(drift, (num_columns, 1))).T
    stochastic = crlted_eps * sdrt_div_col_reshaped * np.sqrt(dt)
    ito_process = drift_reshaped + stochastic
    St = (np.exp(ito_process)).T
    St = np.vstack([np.ones(num_of_risk_factors), St])
    St = S0 * St.cumprod(axis=0)

    # Define t interval correctly
    t = np.linspace(0, years, steps)
    t_column = t.reshape(-1, 1)

    # Require numpy array that is the same shape as St
    tt = np.full(shape=(num_of_risk_factors, steps), fill_value=t).T

    #plt.plot(tt, St)
    #plt.xlabel("Years $(t)$")
    #plt.ylabel("Risk Factirs $(S_t)$")
    #plt.title(
    #    "Realizations of Geometric Brownian Motion\n $dS_t = \mu S_t dt + \sigma S_t dW_t$\n"
    #)
    #plt.show()

    St = np.concatenate((St, t_column), axis = 1)

    St = parce_rf(St, all_df_col_names, report_date)
    St = main(St, deals)
    n += 1
    print(n)
    St['nums'] = n
    mtm_generated = pd.concat([mtm_generated, St])

et = time.time()
elapsed_time = et - st
print('Execution time:', elapsed_time, 'seconds')

#pivot_df = mtm_generated.pivot_table(index='nums', columns='forward_date', values='mtm', aggfunc='sum')
#mtm_generated['forward_date'] = mtm_generated['forward_date'].dt.strftime('%d.%m.%Y')

mtm_generatied_total_bank = mtm_generated.groupby(['forward_date', 'nums'], as_index=False).agg({'mtm': 'sum'}).reset_index()

melted_df = mtm_generatied_total_bank.pivot(index='nums', columns='forward_date', values='mtm').reset_index().melt(id_vars='nums', var_name='forward_date', value_name='mtm')
mtm_generated = mtm_generated.sort_values(by=['forward_date', 'nums'])


# Sort the DataFrame by 'forward_date' for proper plotting of line segments
melted_df.sort_values(by=['nums', 'forward_date'], inplace=True)

# # Plotting line segments
# for num in melted_df['nums'].unique():
#     data_subset = melted_df[melted_df['nums'] == num]
#     plt.plot(data_subset['forward_date'], data_subset['mtm'], marker='o', label=f'nums={num}')
#
# plt.xlabel('forward_date')
# plt.ylabel('mtm')
# plt.title('PFE of Derivatives portfolio')
# #plt.legend()
# plt.grid(True)
# plt.show()

#determine time tenors on which you are going to price MtM + PFE

W1 = report_date + datetime.timedelta(days=1*7)
M1 = report_date + datetime.timedelta(days=4*7)
M3 = report_date + datetime.timedelta(days=3*4*7)
M6 = report_date + datetime.timedelta(days=6*4*7)
Y1 = report_date + datetime.timedelta(days=12*4*7)
Y6 = report_date + datetime.timedelta(days=6*12*4*7)
Y10 = report_date + datetime.timedelta(days=10*12*4*7)

mtm_generated_with_tenors = mtm_generated[mtm_generated['forward_date'].isin([W1, M1, M3, M6, Y1, Y6, Y10])].copy()

grand_final = pd.DataFrame()
client_list = list(set(mtm_generated_with_tenors['client']))
for client in client_list:
    exp_of_the_client = mtm_generated_with_tenors[mtm_generated_with_tenors['client'] == client].copy()
    dates_list = list(set(exp_of_the_client['forward_date']))
    client_metrics = pd.DataFrame()
    for date in dates_list:
        exp_of_the_client_on_date = exp_of_the_client[exp_of_the_client['forward_date'] == date].copy()
        positive_exp = exp_of_the_client_on_date[exp_of_the_client_on_date['mtm'] >= 0]
        negative_exp = exp_of_the_client_on_date[exp_of_the_client_on_date['mtm'] <= 0]
        pfe = positive_exp['mtm'].quantile(0.99)
        epe = positive_exp['mtm'].quantile(0.5)
        ene = negative_exp['mtm'].quantile(0.5)
        result = dict({'client': client, 'date': date, 'pfe': pfe, 'epe': epe, 'ene': ene})
        result = pd.DataFrame([result])
        client_metrics = pd.concat([client_metrics, result], ignore_index=True)
    client_metrics = client_metrics.groupby(['client'], as_index=False).agg({'pfe': 'max', 'epe': 'max', 'ene': 'min'}).reset_index()
    grand_final = pd.concat([grand_final, client_metrics], ignore_index=True)

print(grand_final)

grand_final.to_csv('grand_final.csv')

print('Ok')
